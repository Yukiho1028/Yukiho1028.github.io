<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>咖啡の小记☕</title>
    <link href="/2023/04/02/%E5%92%96%E5%95%A1%E3%81%AE%E5%B0%8F%E8%AE%B0/"/>
    <url>/2023/04/02/%E5%92%96%E5%95%A1%E3%81%AE%E5%B0%8F%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="连锁品牌咖啡">连锁品牌咖啡</h2><p>以下排名不分先后，想到谁就写谁。</p><h3 id="m-stand">M Stand</h3><p><img src="/2023/04/02/%E5%92%96%E5%95%A1%E3%81%AE%E5%B0%8F%E8%AE%B0/m-stand.jpg"></p><p>最开始火起来大概是因为杯子可以吃的<strong>燕麦曲奇拿铁</strong>🍪，但是我绝对不会推荐任何人去喝这款，很小很小一杯而且吃着吃着就腻了，就算会配一杯水也没有用。不过我还是我愿称MStand为奶咖的神，ta家奶咖都很好喝，包括<strong>香烤坚果拿铁</strong>、<strong>黑糖奶咖</strong>，虽然是加了糖的咖啡，但是不会觉得齁，而且这两款都是冷热皆宜。<strong>鲜椰冰咖</strong>🥥也是ta家的一款招牌产品，通过针头将咖啡液注射进一整个椰子里，很清凉，咖啡味不太浓，会配套很完整的餐具，可惜椰子肉有点硬不适合挖着吃。最近(也不是很近了)上新的<strong>布朗尼拿铁</strong>选少糖也可以，小红书上称之为液体布朗尼，很丝滑；有机会下次想去试试<strong>桑格利亚青柚气泡美式</strong>和<strong>咸芝士拿铁</strong>。唯一比较踩雷的是之前上新的一款带水果味冰块的美式，难喝🤮</p><figure><img src="/2023/04/02/%E5%92%96%E5%95%A1%E3%81%AE%E5%B0%8F%E8%AE%B0/MS-coconut.png" alt="鲜椰冰咖"><figcaption aria-hidden="true">鲜椰冰咖</figcaption></figure><h3 id="manner">Manner</h3><p>校内就有一家的平价高品质咖啡，必须好好说道一下。</p><h3 id="tims">Tims</h3><p>是我曾经很喜欢的明星代言过的咖啡，来源于加拿大，甚至在多伦多的咖啡杯上映了明星头像，咖啡整体比较平价，贝果很好吃，天趣球别吃！</p><h3 id="seesaw">Seesaw</h3><p>以前也挺火的，在杭州的天目里开了ta在杭州的第一家分店。</p><h3 id="algebrasit">Algebrasit</h3><p>代数学家源于江苏苏州，近两年开始扩张，比较招牌的是<strong>花蜜咖啡</strong>。</p><h3 id="peets">Peets</h3><p>说到咖啡，怎么能没有咖啡祖师爷皮爷呢。</p><h3 id="costa">Costa</h3><p>相对来说不是很多的连锁店。</p><h3 id="starbucks">Starbucks</h3><p>待更新</p><h3 id="luckin">Luckin</h3><p>待更新</p><p>现在就写到这里，回头有空再更新。</p>]]></content>
    
    
    <categories>
      
      <category>生活随记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Coffee</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Note】STSGCN</title>
    <link href="/2023/04/01/STSGCN/"/>
    <url>/2023/04/01/STSGCN/</url>
    
    <content type="html"><![CDATA[<h3 id="spatial-temporal-synchronous-graph-convolutional-networksa-new-framework-for-spatial-temporal-network-data-forecasting">Spatial-TemporalSynchronous Graph Convolutional Networks:A New Framework forSpatial-Temporal Network Data Forecasting</h3><p>STGCN采用两个分离的模块来捕捉时许和空间的依赖性，只能捕捉节点在同一时间步对邻居节点的影响和对下一时间步的自身的影响，不能直接捕捉节点对下一时间步的邻居节点的影响，而是通过将空间表征喂给时序建模组件来间接捕捉。</p><p>提出STSGCN(Network)，直接同步捕捉局部时空关联，构建了能在一张图中关联邻接时间步内独立的空间图的局部时空图，并构建STSGCM(Module)，在局部时空图中捕捉复杂的局部时空关联。设计了STSGCL(Layer)，在不同的时间段部署STSGCM，最后叠加多层来聚合长范围时空关联和异质性用于预测。模型整体架构如下图所示。</p><p><img src="/2023/04/01/STSGCN/Model_Archi.png"></p><p>定义空间网络<span class="math inline">\(\mathcal{G}=(V,E,A)\)</span>，<span class="math inline">\(V\)</span>表示<span class="math inline">\(N\)</span>个顶点的集合，<span class="math inline">\(E\)</span>表示边集合，<span class="math inline">\(A\)</span>表示网络<span class="math inline">\(\mathcal{G}\)</span>的邻接矩阵；定义图信号矩阵<span class="math inline">\(X^{(t)}_\mathcal{G}\in\R^{N\timesC}\)</span>表示在时间步<span class="math inline">\(t\)</span>空间网络<span class="math inline">\(\mathcal{G}\)</span>的观测情况，<span class="math inline">\(C\)</span>表示特征的数量。</p><p>问题定义，学习函数<span class="math inline">\(f\)</span>，使得<span class="math inline">\(f(X^{(t-T+1)}_\mathcal{G},X^{(t-T+2)}_\mathcal{G},...,X^{(t)}_\mathcal{G})=(X^{(t+1)}_\mathcal{G},X^{(t+2)}_\mathcal{G},...,X^{(t+T&#39;)}_\mathcal{G})\)</span></p><p><strong>局部时空图构建</strong></p><p><span class="math inline">\(A\in\R^{N\timesN}\)</span>表示空间图的邻接矩阵，<span class="math inline">\(A&#39;\in\R^{3N\times3N}\)</span>表示在三个连续的空间图上构建的局部时空图的邻接矩阵，时间步<span class="math inline">\(t_1\)</span>上的节点<span class="math inline">\(i\)</span>在时间步<span class="math inline">\(t_2\)</span>和<span class="math inline">\(t_3\)</span>的节点索引分别为<span class="math inline">\(N+i\)</span>和<span class="math inline">\(2N+i\)</span>。对角线上表示3个连续时间步空间网络的邻接矩阵，对角线的两侧表示每个节点自身在邻接时间步的连通性。</p><p><img src="/2023/04/01/STSGCN/Adj_Matrix.png"></p><p><strong>时空嵌入temporal embedding</strong></p><p>在一张图中连接不同时间步中的节点，模糊了每个节点的时间属性。为更好地建模时空关联，在时空网络序列中加入位置嵌入，同时考虑到空间和时间的信息。对时空网络序列<span class="math inline">\(X_\mathcal{G}\in\R^{N\times C\timesT}\)</span>，设计一个可学习的时间嵌入矩阵<span class="math inline">\(T_{emb}\in\R^{C\timesT}\)</span>和空间嵌入矩阵<span class="math inline">\(S_{emb}\in\R^{N\timesC}\)</span>，经训练后包含必要的时空信息。通过广播操作把两个嵌入矩阵加入到时空网络序列中获得网络序列的新的表示：<span class="math inline">\(X_{\mathcal{G}+t_{emb}+s_{emb}}=X_\mathcal{G}+T_{emb}+S_{emb}\in\R^{N\timesC\times T}\)</span>.</p><p><strong>时空同步图卷积模块STSGCM</strong></p><p>图卷积的输入是局部时空图的图信号矩阵，每个节点聚合了自身和邻居节点在邻接时间步的特征，聚合函数是一个线性函数，其权重与节点和其邻居的边的权重相同，然后部署一个带有激活函数的全连接层把节点特征转换到一个新空间，卷积操作可以用公式表示为<span class="math inline">\(GCN(h^{(l-1)})=h^{(l)}=\sigma(A&#39;h^{(l-1)}W+b)\in\R^{3N\timesC&#39;}\)</span>，其中<span class="math inline">\(A&#39;\in\R^{3N\times3N}\)</span>，<span class="math inline">\(h^{(l-1)}\in\R^{3N\timesC}\)</span>表示第<span class="math inline">\(l\)</span>层的输入，可学习参数<span class="math inline">\(W\in\R^{C\timesC&#39;},b\in\R^{C&#39;}\)</span>，激活函数<span class="math inline">\(\sigma\)</span>为<span class="math inline">\(GLU\)</span>，控制哪些信息被传递到下一层，图卷积层可以表示为<span class="math inline">\(h^{(l)}=(A&#39;h^{(l-1)} W_1+b_1)\otimes\mathcal{sigmoid}(A&#39;h^{(l-1)}W_2+b_2)\)</span>，其中可学习参数<span class="math inline">\(W_1\in\R^{C\times C&#39;},W_2\in\R^{C\timesC&#39;},b_1\in\R^{C&#39;},b_2\in\R^{C&#39;}\)</span>。</p><p>AGG层包含聚合(aggregating)与裁剪(cropping)两步：聚合采用最大池化层，需要所有输出具有同样的大小，所以一个模块内的图卷积操作的内核数应当相等，聚合操作的公式表示为<span class="math inline">\(h_{AGG}=max(h^{(1)},h^{(2)},...,h^{(L)})\in\R^{3N\timesC_{out}}\)</span>，<span class="math inline">\(C_{out}\)</span>表示内核数；裁剪用于移除节点在过去和未来时间步的所有特征，去除冗余信息。</p><p><img src="/2023/04/01/STSGCN/STSGCM.png"></p><p>如上图所示，STSGCM的输入为一个局部时空图信号矩阵<span class="math inline">\(h^{(0)}\in\R^{3N\timesC_{in}}\)</span>，经历多个图卷积操作后输出<span class="math inline">\(h^{(i)}\in\R^{3N\timesC_{out}}\)</span>喂给AGG层，先聚合得到<span class="math inline">\(h_{AGG}\in\R^{3N\timesC_{out}}\)</span>，经裁剪后得到最后输出<span class="math inline">\(h^{(final)}\in\R^{N\times C_{out}}\)</span>。</p><p><strong>时空同步图卷积层STSGCL</strong></p><p>采用滑动窗口来分不同的时间段，在一个STSGCL中部署多个STSGCMs，各自在不同的时间段上建模局部时空关联，以此捕捉长距时空特征。输入矩阵<span class="math inline">\(X\in\R^{T\times N\timesC}\)</span>，滑动窗口将输入切分成<span class="math inline">\(T-2\)</span>个时空网络序列<span class="math inline">\(X\in\R^{3\times N\times C}\)</span>，重塑为<span class="math inline">\(X&#39;_{reshape}\in\R^{3N\timesC}\)</span>直接喂给STSGCM。一层STSGCL部署了<span class="math inline">\(T-2\)</span>个STSGCMs，他们的输出被拼接成一个矩阵，作为STSGCL的最后输出，公式为<span class="math inline">\(M=[M_1,M_2,...,M_{T-2}]\in\R^{(T-2)\times N\timesC_{out}}\)</span>，<span class="math inline">\(M_i\in\R^{N\timesC_{out}}\)</span>表示第<span class="math inline">\(i\)</span>个STSGCM的输出。</p><p><img src="/2023/04/01/STSGCN/STSGCL.png"></p><p><strong>Mask matrix</strong></p><p>增加一个可学习的掩码矩阵<span class="math inline">\(W_{mask}\in\R^{3N\times3N}\)</span>，与表示聚合权重的邻接矩阵<span class="math inline">\(A&#39;\)</span>作点积，得到基于权重调整的局部邻接矩阵<span class="math inline">\(A&#39;_{adjusted}=W_{mask}\otimesA&#39;\in\R^{3N\times 3N}\)</span>。</p><p><strong>Input layer</strong></p><p>在最开始设置一个全连接层以转换输入到一个高维空间，提升网络的可表示性。</p><p><strong>Output layer</strong></p><p>将最后一层STSGCL的输出通过转置和修改输入矩阵的大小，再经过数量为<span class="math inline">\(T&#39;\)</span>的两个全连接层，最后拼接来得到期望的预测。</p><p><strong>Loss function</strong></p><p>采用相比均方误差敏感度小一些的Huber loss来计算loss。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Traffic Forecasting</tag>
      
      <tag>GCN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Note】STGCN</title>
    <link href="/2023/04/01/STGCN/"/>
    <url>/2023/04/01/STGCN/</url>
    
    <content type="html"><![CDATA[<h3 id="spatio-temporal-graph-convolutional-networksa-deep-learning-framework-for-traffic-forecasting">Spatio-TemporalGraph Convolutional Networks:A Deep Learning Framework for TrafficForecasting</h3><p>在文中提出的图时空网络STGCN中，定义<span class="math inline">\(v^t\in\R^n\)</span>为<span class="math inline">\(n\)</span>个观测点在时间戳<span class="math inline">\(t\)</span>时的观测向量，<span class="math inline">\(\mathcal {G}_t=(\mathcal {V}_t,\mathcal{E},W)\)</span>，<span class="math inline">\(\mathcal{V}_t\)</span>表示顶点(观测点)的集合，<span class="math inline">\(\mathcal {E}\)</span>表示边的集合，<span class="math inline">\(W\in \R^{n\times n}\)</span>为<span class="math inline">\(\mathcal{G}_t\)</span>的邻接权重矩阵。网络的输入为<span class="math inline">\(M\)</span>个时间步的图的特征向量<span class="math inline">\(X\in R^{M\times n\times C_i}\)</span>，<span class="math inline">\(n\)</span>表示观测点的数量，<span class="math inline">\(C_i\)</span>是数据的特征向量长度，在文中取1，接下来对模型整体架构展开介绍。</p><p><strong>空域卷积</strong>在每个时间步的图上进行，输入<span class="math inline">\(X\in R^{n\timesC_i}\)</span>，用Chebyshev多项式近似与一阶近似后的图卷积公式，使得在卷积过程中不仅考虑邻居节点的状态，也考虑自身的状态，再对图卷积运算进行泛化。对于完整的时空图(即对应<span class="math inline">\(M\)</span>个时间步)，其输入为<span class="math inline">\(X\in\R^{M\times n\times C_i}\)</span>，输出为<span class="math inline">\(Y\in \R^{M\times n\times C_o}\)</span></p><p><img src="/2023/04/01/STGCN/Temporal_Block.png"></p><p>如上图所示，在最右侧的<strong>时域卷积块</strong>中，每个节点处的输入<span class="math inline">\(X\in \R^{M\timesC_i}\)</span>，沿着时间维度进行一维卷积，时间卷积探索<span class="math inline">\(K_t\)</span>个输入的邻居每次将序列长度缩短<span class="math inline">\(K_t-1\)</span>，那么每个有着<span class="math inline">\(C_i\)</span>个通道的序列长度为<span class="math inline">\(M\)</span>的节点的输入可以表示为<span class="math inline">\(Y\in \R^{M\times C_i}\)</span>，卷积核 <span class="math inline">\(\Gamma \in \R^{K_t\times C_i\times2C}\)</span>再将<span class="math inline">\(Y\)</span>映射为独立的输出元素<span class="math inline">\([P\ Q]\in \R^{(M-K_t+1)\times(2C_O)}\)</span>，分别通过<span class="math inline">\(GLU\)</span>激活，<em>sigmoid</em>$ 门$<span class="math inline">\(\sigma(Q)\)</span>控制着当前状态的哪个输入<span class="math inline">\(P\)</span>与发现时间序列中的组成结构和动态变化相关，非线性门通过堆叠的时间层挖掘输入域。此外，在堆叠的时间卷积层中使用残差连接。同理，可以将卷积核应用于图中的<span class="math inline">\(n\)</span>个节点，得到最后的输出<span class="math inline">\(\mathcal{Y}\in \R^{(M-K_t+1)\times n\timesC}\)</span>。时间门卷积的公式为<span class="math inline">\(\Gamma *_\TauY=P\odot \sigma(Q)\in \R^{(M-K_t+1)\times C_o}\)</span>。</p><p>注：这里对映射输出为单独的P和Q两个元素的方法和原因还不太理解。</p><p><img src="/2023/04/01/STGCN/ST_Conv_Block.png"></p><p>如上图所示，中间的<strong>时空卷积块</strong>(ST-ConvBlock)由两个时域卷积块和一个空域卷积块组成，时空卷积块的输入和输出均为3D张量，对于第<span class="math inline">\(l\)</span>个块，输入为<span class="math inline">\(v^l\in \R^{M\times n\timesC^l}\)</span>，输出为<span class="math inline">\(v^{l+1}\in\R^{(M-2(K_t-1))\times n\times C^{l+1}}\)</span>，计算方式为<span class="math inline">\(v^{l+1}=\Gamma^l_1*_\mathcal{T}ReLU(\Theta^l*_\mathcal {G}(\Gamma^l_0*_\mathcal{T}v^l))\)</span>，其中<span class="math inline">\(\Gamma^l_0\)</span>和<span class="math inline">\(\Gamma^l_1\)</span>分别为时空块<span class="math inline">\(l\)</span>内上面和下面的卷积核，<span class="math inline">\(\Theta^l\)</span>是图卷积的谱内核。通过图卷积层对通道进行下缩放和上缩放，实现尺度压缩和特征压缩。</p><p><img src="/2023/04/01/STGCN/Output.png"></p><p>根据时域卷积块的一维卷积，每经过一个时空卷积块，数据在时间维度的长度减小<span class="math inline">\(2(K_t-1)\)</span>，在叠加两个时空卷积块后，输出<span class="math inline">\(Y\in\R^{(M-4(K_t-1))\times n\timesC_o}\)</span>。输出层包括一个时间卷积层和一个全连接层，时间卷积层把第二个时空卷积块的输出映射为单步预测，得到输出<span class="math inline">\(Z\in\R^{n\times c}\)</span>，全连接层通过在<span class="math inline">\(c\)</span>个通道上应用线性变换计算<span class="math inline">\(n\)</span>个节点在<span class="math inline">\(t+1\)</span>时间点的预测值<span class="math inline">\(\hat{v}=Zw+b\)</span>，其中权重参数<span class="math inline">\(w\in\R^c\)</span>。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Traffic Forecasting</tag>
      
      <tag>GCN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Note】Fed-LTD</title>
    <link href="/2023/04/01/Fed-LTD/"/>
    <url>/2023/04/01/Fed-LTD/</url>
    
    <content type="html"><![CDATA[<h3 id="fed-ltdtowards-cross-platform-ride-hailing-via-federated-learning-to-dispatch">Fed-LTD:TowardsCross-Platform Ride Hailing via Federated Learning to Dispatch</h3><p>派单效率受到数据隔离问题(data isolationproblem)的影响，本文提出Fed-LTD框架，实现多平台在不共享本地数据的前提下协作派单，提供隐私保护的同时共享派单模型和决策。</p><p>挑战：</p><ol type="1"><li>如何最大化跨平台派单的总使用率——高效聚合本地派单决策(二分图)</li><li>如何在联合派单的情况下实现隐私保护和高效</li></ol><h4 id="问题建模">问题建模</h4><p><strong><em>Drivers Set.</em></strong> 司机集合<span class="math inline">\(U\)</span>，<span class="math inline">\(u\inU\)</span>，<span class="math inline">\(u.loc\)</span>表示司机的位置</p><p><strong><em>Orders Set.</em></strong> 订单集合<span class="math inline">\(V\)</span>， <span class="math inline">\(v\inV\)</span>，<span class="math inline">\(v.origin,v.destination,v.reward\)</span>分别表示订单的出发地、目的地和订单价格</p><p>在二分图 <span class="math inline">\(G=(U\cup V,E)\)</span>中，边<span class="math inline">\(e=(e,v)\)</span> 的权重 <span class="math inline">\(w(u,v)=v.reward\)</span>，当<span class="math inline">\(u.loc\)</span> 和 <span class="math inline">\(v.origin\)</span> 之间的距离超过一定的阈值<span class="math inline">\(R\)</span> 后，对应的边会被剪枝</p><p><strong><em>Matching Allocation.</em></strong> <span class="math inline">\(\mathcal{M}\)</span> 表示一个对二分图 <span class="math inline">\(G=(U\cup V,E)\)</span> 的派单策略，<span class="math inline">\((u,v)\)</span> 满足 <span class="math inline">\(u\in U,v\in V\)</span>且<span class="math inline">\(u\)</span> 和<span class="math inline">\(v\)</span>都只在<span class="math inline">\(\mathcal{M}\)</span>中出现过一次，通过计算派单策略<span class="math inline">\(\mathcal{M}\)</span>下的边权和定义使用率函数(utilityfunction) <span class="math display">\[SUM(\mathcal{M}(G))=\sum_{(u,v)\in \mathcal{M}}w(u,v)\]</span> <strong><em>Order Dispatching Problem.</em></strong>给定batch序列 <span class="math inline">\(&lt;1,2,...,T&gt;\)</span> ，<span class="math inline">\(t\)</span>的上一个batch就抵达的订单和司机可以构建当前的二分图 <span class="math inline">\(G^{(t)}\)</span>，目标是找到最佳分配策略 <span class="math inline">\(\mathcal {M}^{(t)}\)</span>使得所有batch的使用率和最高 <span class="math display">\[max\sum_{t=1}^TSUM(\mathcal {M}^{(t)}(G^{(t)}))\]</span> 有 <span class="math inline">\(K\)</span> 个平台<span class="math inline">\(P_1,P_2,...,P_K\)</span>和一个服务器 <span class="math inline">\(S\)</span>，每个平台 <span class="math inline">\(P_k\)</span> 有一个本地二分图 <span class="math inline">\(G_K=(U_k\cupV_k,E_k)\)</span>，里面的节点对应该平台的司机和订单</p><p><strong><em>Global Optimum.</em></strong> <span class="math inline">\(G\)</span> 为全局二分图，全局最优 <span class="math inline">\(\mu(G)\)</span>可以理解为在非联邦设置下的最优匹配结果 <span class="math display">\[\mu(G)=\mathop{max}_{&lt;\mathcal{M}^{(t)}&gt;}\sum_{t=1}^TSUM(\mathcal{M}^{(t)}(G^{(t)}))\]</span> <strong><em>Summation of Local Optimum.</em></strong> <span class="math inline">\(\mu(G_{LS})\)</span> 是本地所有二分图的联合 <span class="math display">\[\mu(G_{LS})=\sum_{k=1}^K\mu(G_k)\]</span> 每个平台的信息共享策略可以被定义为一个子图序列，<span class="math inline">\(K\)</span> 个平台即 <span class="math inline">\(&lt;\mathcal{G}_1,...,\mathcal{G}_K&gt;\)</span>，其中<span class="math inline">\(\mathcal {G}=\cup_{k=1}^K\mathcal{G}_k\)</span>，对于全局最优，<span class="math inline">\(\mathcal{G}_k=G_k\)</span>，对于本地最优的和，<span class="math inline">\(\mathcal{G}_k=\mathbb {0}\)</span></p><p><strong><em>Federated Order Dispatching Problem(FOD).</em></strong>要找到<span class="math inline">\(G_{Fed}=G_{LS}\cup\mathcal{G}\)</span> 的信息共享策略 <span class="math inline">\(&lt;\mathcal{G}_1,...,\mathcal{G}_K&gt;\)</span>使得 <span class="math display">\[\mu(G_{Fed})-\mu(G_{LS})&gt;\Delta\]</span> 目标是使得 <span class="math inline">\(\Delta\)</span>尽可能大，在满足隐私限制的前提下，使联合订单分配达到与全局最优相似的表现</p><h4 id="算法介绍">算法介绍</h4><p><strong><u>本地学习和派单(Local learning anddispatching)</u></strong></p><p>将司机作为agents，司机的地理位置(六边形网格表示)作为states，接单或保持空闲作为actions，价值函数是从某个状态得到的期望累积奖励，即<span class="math inline">\(\mathcal{V}(s^{(t)})=\mathbb{E}[\sum_tr^{(t)}|s^{(t)}]\)</span>，其中<span class="math inline">\(s^{(t)}、r^{(t)}\)</span>分别表示batcht内的状态向量和奖励和，价值函数的更新遵循贝尔曼方程，其中，<span class="math inline">\(\alpha_l、\gamma\)</span>分别表示学习率和折扣因子。 <span class="math display">\[\mathcal{V}(𝑠^{(t)})\leftarrow\mathcal{V}(𝑠^{(t)})+\alpha_𝑙·\sum_u(r_u^{(t)}+\gamma\mathcal{V}(s_v^{(t+1)})-\mathcal{V}(s_u^{(t)}))\]</span>每个平台根据已学到的价值做分单决策。将未来奖励的期望通过时间差分误差(TDerror)编码为二分图的边权重 <span class="math display">\[w(u,v)=v.reward+\gamma\mathcal{V}(s_v^{(t+1)})-\mathcal{V}(s_u^{(t)})\]</span></p><p>重建二分图后，采用基于匈牙利方法的二分图最大匹配做本地分配决策。每个平台可以独立地在本地运行，服务器将所有平台的奖励和相加作为baseline(本实验中即LocalSum)</p><p><strong><u>分配模型聚合(Aggregation of DispatchingModels)</u></strong></p><p><strong>随机掩码下的隐私聚合——针对聚合期间的隐私泄露</strong></p><p>采用随机掩码(randommasking)模糊已升级的网格状态来保护值更新的隐私，<span class="math inline">\(\Delta \mathcal{V}_k\)</span> 是平台 <span class="math inline">\(k\)</span>更新后的价值表，通过下面的掩码方法实现扰乱<span class="math inline">\(\Delta \mathcal{V}_k\)</span> 的值 <span class="math display">\[\Delta\tilde{\mathcal{V}_k}=\Delta\mathcal{V}_k+\sum_{k&#39;&lt;k}PRG(sd_{k,k&#39;})-\sum_{k&#39;&lt;k}PRG(sd_{k&#39;,k})\]</span> <span class="math inline">\(PRG(·)\)</span>是一个伪随机生成器，<span class="math inline">\(sd_{k,k&#39;}\)</span>是一个由平台<span class="math inline">\(k,k&#39;\)</span> 通过密钥协商算法(key agreementalgorithm)生成的随机种子。如下图所示，没有随机掩码的情况下更容易被推断哪个网格被更新了，而随机掩码后敏感信息就难以推断了。</p><p><img src="/2023/04/01/Fed-LTD/random_masking.png"></p><p><strong>推迟同步——针对服务器和各平台之间的高通讯代价</strong></p><p>服务器从每个batch同步一次推迟至每 <span class="math inline">\(t_d\)</span>个batches进行一次值同步，将通讯代价减少了<span class="math inline">\(1/t_d\)</span></p><p><strong><u>分配决策聚合(Aggregation of DispatchingDecisions)</u></strong></p><p><strong>重建全局二分图</strong></p><p>设计基于局部敏感哈希(Locality Sensitive Hashing,LSH)的方法平衡隐私和效率，在哈希后依旧保持了最近邻组合 <span class="math display">\[\text{If } dist(u,v)\le R,\text{  then }Pr[h(u)=h(v)]\ge p_1\\\text{If } dist(u,v)\ge c·R,\text{  then }Pr[h(u)=h(v)]\le p_2\]</span> <span class="math inline">\(dist(·,·)\)</span>表示欧几里得距离，<span class="math inline">\(R\)</span>是连接性阈值(比如3km)， <span class="math inline">\(h\)</span>是哈希函数</p><p>通过LSH编码，可以生成由 <span class="math inline">\(\mathcal{K}\)</span> 个哈希函数表示的一个节点<span class="math inline">\(v\)</span> 的签名 <span class="math inline">\(Sig(v)=&lt;h_1(v),···，h_{\mathcal{K}}(v)&gt;\)</span>，再采用MD5编码哈希函数来保护LSH编码中的相关位置，加密后的签名为<span class="math inline">\(SSig(v)=MD5(Concat(h(v))\)</span>，种子 <span class="math inline">\(Concat(h(v))\)</span>是 <span class="math inline">\(\mathcal{K}\)</span>个二元哈希编码的拼接。编码算法生成要共享的节点的加密签名，服务器通过解码重建二分图。</p><p><strong>差分隐私混淆边权</strong></p><p>恢复全局二分图结构后，需要计算由强化学习生成的边权。<span class="math inline">\(v.origin\)</span> 和 <span class="math inline">\(u.loc\)</span> 相近，根据价值函数的连续性，有<span class="math inline">\(\mathcal{V}(v.origin)\approx\mathcal{V}(u.loc)\)</span>，那么权重的计算公式可以重写为如下只与订单<span class="math inline">\(v\)</span> 有关的公式 <span class="math display">\[w(u,v)\approxv.reward+\gamma\mathcal{V}(v.destination)-\mathcal{V}(v.origin)\]</span> 采用差分隐私来扰动 <span class="math inline">\(w(u,v)\)</span>，服务器就难以通过网格值推断订单和司机的位置。将Laplace噪声加入到边权计算中，敏感度可以通过<span class="math inline">\(\Delta_{\mathcal{V}}=\gamma\mathcal{V}_{max}-\mathcal{V}_{min}-(\gamma\mathcal{V}_{min}-\mathcal{V}_{max})=(1+\gamma)diam(\mathcal{V})\)</span>计算，其中<span class="math inline">\(diam(\mathcal{V})=\mathcal{V}_{max}-\mathcal{V}_{min}\)</span>，那么扰动可以写为<span class="math display">\[\tilde{w}(v)=w(u,v)+Lap(\frac{(1+\gamma)diam(\mathcal{V})}{\epsilon_p})\]</span> 其中，<span class="math inline">\(\epsilon_p\)</span>为隐私预算(privacy budget)。假设 <span class="math inline">\(v\)</span>和 <span class="math inline">\(v&#39;\)</span>为两个有同样奖励但任意的起点和目的地，根据Laplace机制，有 <span class="math display">\[\frac{Pr[\tilde{w}(v)=w]}{Pr[\tilde{w}(v&#39;)=w]}\leexp(\frac{\epsilon_p}{(1+\gamma)diam(\mathcal{V})}|w(v)-w(v&#39;)|)\lee^{\epsilon_p}\]</span> 该公式表示在扰动后难以区分两个订单(<span class="math inline">\(v\)</span> 和 <span class="math inline">\(v&#39;\)</span>)，服务器难以从边权推断该条边属于哪个订单。每个平台上传经干扰后的边权。最后服务器用贪心算法实现全局匹配，每个平台的司机都可以得到额外的来自其他平台的订单。</p><h4 id="算法流程">算法流程</h4><p><img src="/2023/04/01/Fed-LTD/framework.png"></p><ol type="1"><li><p>本地学习和派单：每个平台本地学习一个价值函数并基于价值函数做分单决策</p></li><li><p>聚合分配模型：将联邦学习用于聚合分配模型，同时考虑到隐私保护和效率优化</p></li><li><p>聚合分配决策：通过聚合本地的残差二分图(每个平台未匹配的节点)共享分配决策</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Federated Learning</tag>
      
      <tag>Reinforcement Learning</tag>
      
      <tag>Order Dispatch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Note】LTA</title>
    <link href="/2023/04/01/LTA/"/>
    <url>/2023/04/01/LTA/</url>
    
    <content type="html"><![CDATA[<h3 id="learning-to-assigntowards-fair-task-assignment-in-large-scale-ride-hailing">Learningto Assign:Towards Fair Task Assignment in Large-Scale Ride Hailing</h3><p>采用强化学习全面地分配任务，并提出一些加速技巧实现对大规模数据的快速公平的分配。</p><p>从司机视角考虑，不公平的分配策略影响司机的感受(the fairness ofearnings among drivers)</p><p>挑战：</p><ol type="1"><li>在线设置online setting：高维的时空依赖和变化</li><li>双目标优化bi-objectiveoptimization：在变化的实际限制下同时优化司机的使用率和公平性</li><li>高效率要求high efficiency requirement：市区数据的快速任务分配</li></ol><p>现有的方法的问题：短视，忽略了当前任务分配对未来的影响，缩减了优化空间且降低了利用率和公平性；依赖线性规划或需要多重再分配，在大规模数据上的处理实时响应时效率低下。</p><p>衡量指标：</p><p>使用率utility——所有司机的收入总和</p><p>公平性fairness——一定时间内司机收入的公平性</p><p>本文提出的方法中，通过强化学习学习未来感知的任务策略，将使用率和公平性嵌入到同一个增强操作，并利用二分图的稀疏性实现加速；还提出了一个带权的分期偿还的公平性矩阵来刻画更精细时间粒度下司机收入的公平性。</p><h4 id="问题建模">问题建模</h4><p>将时间 <span class="math inline">\(T\)</span>分为多个batch <span class="math inline">\(t\)</span> ，<span class="math inline">\(W\)</span> 和 <span class="math inline">\(R\)</span> 分别表示在 <span class="math inline">\(T\)</span> 内的司机集合和需求集合</p><p><strong><em>Request.</em></strong> 一个订单需求<span class="math inline">\(r\in R\)</span> 用元组<span class="math inline">\(&lt;o_r,d_r.p_r,\tau _r&gt;\)</span> 表示，其中<span class="math inline">\(o_r,d_r.p_r,\tau _r\)</span>分别表示需求<span class="math inline">\(r\)</span>的出发地、目的地、价格和持续时间</p><p><strong><em>Driver.</em></strong> 一个出租车司机 <span class="math inline">\(w\in W\)</span> 用元组 <span class="math inline">\(&lt;l_w^{(t)},u_w^{(t)},a_w^{(t)}&gt;\)</span>表示，其中<span class="math inline">\(l_w^{(t)},u_w^{(t)},a_w^{(t)}\)</span>分别表示在<span class="math inline">\(t\)</span> 内司机 <span class="math inline">\(w\)</span> 的当前位置、收入和状态。<span class="math inline">\(a_w^{(t)}\)</span>为0表示司机处于inactive状态(比如不在线)，为1表示司机处于active状态(正在服务一个需求或空闲)，假设一个batch内司机的<span class="math inline">\(a_w^{(t)}\)</span>不变；若司机在 <span class="math inline">\(t\)</span> 内处于空闲状态，则收入为零，即 <span class="math inline">\(u_w^{(t)}=0\)</span>，若在 <span class="math inline">\(t\)</span> 内服务一个需求，则收入为 <span class="math inline">\(u_w^{(t)}=p_r/\tau _r\)</span></p><p>P.S.本文考虑到更真实的司机设置依赖，即未来的司机分布会受当前batch内的司机分布和任务分配影响</p><p><strong><em>Bipartite Graph.</em></strong> 候选任务集用二分图 <span class="math inline">\(G^{(t)}=&lt;R^{(t)},W^{(t)},E^{(t)}&gt;\)</span>表示，其中<span class="math inline">\(R^{(t)},W^{(t)}\)</span>分别表示 <span class="math inline">\(t\)</span> 内待分配的订单和空闲司机。若需求 <span class="math inline">\(r\)</span> 被分配给司机 <span class="math inline">\(w\)</span>，那么就有一条权重为 <span class="math inline">\(\theta _{r,w}\)</span>的边 <span class="math inline">\((r,w)\in E^{(t)}\)</span> 连接需求 <span class="math inline">\(r\)</span> 和司机 <span class="math inline">\(w\)</span></p><p>另外，需要设置距离上限，当需求-司机的距离小于该阈值时才存在连接两者的边，同时给每条边<span class="math inline">\((r,w)\)</span>设置一个投影率<span class="math inline">\(\lambda_{r,w}\)</span>表示其他用户体验相关的因素。距离阈值和投影率均由平台给出，权重<span class="math inline">\(\theta_{r,w}\)</span> 初始化为需求 <span class="math inline">\(r\)</span> 的价格 <span class="math inline">\(p_r\)</span></p><p><strong><em>Total Utility.</em></strong> 给定可重用司机集合 <span class="math inline">\(W\)</span>和动态出现的需求集合 <span class="math inline">\(R\)</span>，总使用率通过所有司机在总时间 <span class="math inline">\(T\)</span> 内的期望累积收入总和来表示。最大化<span class="math inline">\(U\)</span> 来优化所有司机的总收入 <span class="math display">\[U=\sum_{w\in W}\mathbb {E}[\sum_{t\in T}u_w^{(t)}]\]</span> <span class="math inline">\(M\)</span>表示一个有利于优化总使用率和收入公平性的匹配策略。司机 <span class="math inline">\(w\)</span> 的期望累积收入<span class="math inline">\(\mathbb {E}[\sum_{t\inT}u_w^{(t)}]\)</span>由匹配结果来决定 <span class="math display">\[\mathbb {E}[\sum_{t\in T}u_w^{(t)}]=\sum_{t\in T}\sum_{(r,w)\inM^{(t)}}(1-\lambda_{w,r})·p_r\]</span> <strong><em>Weighted Amortized Fairness.</em></strong> <span class="math inline">\(F_w\)</span> 是司机 <span class="math inline">\(w\)</span> 在加权活跃时间内带权分摊的公平性，其中<span class="math inline">\(\xi^{(t)}\)</span>是用于标准化一天内不同时间段潜在收入方差的权重 <span class="math display">\[F_w= \frac {\sum_{t\in T} u_w^{(t)}/\xi^{(t)}}{\sum_{t\in T}a_w^{(t)}}\]</span> <strong><em>Temporal Earnings Fairness.</em></strong>收入公平性由带权分摊公平度的熵变量来衡量. 大的 <span class="math inline">\(F\)</span>表示司机间更为分散的带权分摊公平度，比如不公平的收入分配，所以目标是最小化<span class="math inline">\(F\)</span> <span class="math display">\[F=-\sum_{w\in W}log(\frac{F_w}{max_{w\in W&#39;}F_{w&#39;}})\]</span></p><h4 id="算法介绍">算法介绍</h4><p><strong><u>基于学习的Re-weighting</u></strong></p><p><strong>线上学习公式化</strong></p><p>司机 <span class="math inline">\(w\)</span> 在状态<span class="math inline">\((l_w^{(t)},t)\)</span> 下遵循策略 <span class="math inline">\(\pi\)</span> 的价值函数<span class="math inline">\(V_w^{\pi}(l_w^{(t)},t)\)</span>，通过奖励(rewards)迭代更新价值函数 <span class="math display">\[V_w^{\pi}(l_w^{(t)},t)\leftarrowV_w^{\pi}(l_w^{(t)},t)+\beta·\Delta_w(\forall w\in W)\]</span> <span class="math inline">\(\beta\)</span>是学习率，<span class="math inline">\(\Delta_w\)</span> 的定义如下 <span class="math display">\[\Delta_W=\begin{cases}&amp; p_r+V_w^{\pi}(d_r,t+\tau_r)-V_w^{\pi}(l_w,t)\quad \text{if w getsr}\\&amp; 0 \quad \text{if w is idle}\end{cases}\]</span> <strong>减少状态数量</strong></p><p>初始状态数可以表示为 <span class="math inline">\(N_S \timesN_T\)</span>，空间状态数乘时间状态数，通过以下两种方式减少状态(states)数量：</p><p>·空间价值函数估计。将时空状态空间中的原始价值函数估计为仅考虑空间状态的形式，举例，<span class="math inline">\(V_w(d_r,t+\tau _r)=V_w(d_r,t)\)</span>忽略了短暂时间内的状态变化(订单时间一般较短，可以假设不变). 折扣因子 $$用于修正对长持续时间的需求的估计的不准确性. 状态数变化：<span class="math inline">\(N_T ·N_S \rightarrow N_T\)</span> <span class="math display">\[\Delta_W=\begin{cases}&amp; p_r+\gamma ^{\tau _r}V_w(d_r,t)-V_w(l_w)\quad \text{if w gets r}\\&amp; 0 \quad \text{if w is idle} \end{cases}\]</span> · Agents间的信息共享。采用合并了所有Agents的价值函数的共享价值函数，更新公式可简化为 <span class="math display">\[V(l)\leftarrow V(l)+\beta&#39;·\sum_{w:l_w^{(t)}\in l}\Delta_w\]</span> 其中 <span class="math inline">\(\beta&#39;\)</span>是标准化后的学习率，<span class="math inline">\(l\)</span>表示价值函数所有可能的位置</p><p><strong>适应不同市区布局</strong></p><p>将位置离散化为两层结构并分别平滑不同层的价值函数.将城市分为六边形/四边形，有多个方向的六边形适合不规则的城市布局，与经纬度平行的四边形适合用于规则区域。按以下方式平滑价值函数<span class="math display">\[V(l)=\frac{1}{|DIR_H|+|DIR_S|}(\sum_{x\in DIR_H}H(l+x)+\sum_{x\inDIR_S}S(l+x))\]</span> 其中 <span class="math inline">\(S\)</span> 和 <span class="math inline">\(H\)</span> 分别表示六边形和四边形的价值函数，<span class="math inline">\(DIR_H\)</span> 和 <span class="math inline">\(DIR_S\)</span> 明确了两层中平滑指向的偏移量.</p><p><strong>避免线上学习的冷启动</strong></p><p>(Guding)价值函数初始化为0，导致初始的batch中的任务分配难以考虑到未来情况，需要引导司机提前到合适的区域避免冷启动</p><p><strong><u>双目标任务分配</u></strong></p><p><strong>公平度提升</strong></p><p>(Guiding)直接将公平性检查嵌入最大化总使用率的过程。采用KM算法，先找到一条包含连接和未连接的边的道路，若未连接的边权重大于已连接的边的权重，交换两条边提升总使用率；当搜索一条增广路时，检查司机未来的收入率并拒绝有较大收入率方差的增强；为减少检查量和时间消耗，只检查邻接的两个司机间的增强道路。</p><p><strong>加速</strong></p><p>(Assigning)采用宽度优先搜索(BFS)，将二分图分成多个部分，每个部分可能只有一个司机/需求。</p><h4 id="算法流程">算法流程</h4><p><img src="/2023/04/01/LTA/Workflow.png"></p><p>首先re-weighting模块结合跨任务的时间依赖精细化给定二分图的边权重，然后双目标任务模块通过公平性增强和其他加速策略找到分配策略，最后基于学习的re-weighting模块再基于分配结果更新权重，并在某些情况下指引空闲司机到指定区域。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Reinforcement Learning</tag>
      
      <tag>Order Dispatch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Note】Large-Scale Order Dispatch</title>
    <link href="/2023/04/01/Large-Scale%20Order%20Dispatch%20in%20On-Demand%20Ride-Hailing%20Platforms%20A%20Learning%20and%20Planning%20Approach/"/>
    <url>/2023/04/01/Large-Scale%20Order%20Dispatch%20in%20On-Demand%20Ride-Hailing%20Platforms%20A%20Learning%20and%20Planning%20Approach/</url>
    
    <content type="html"><![CDATA[<h3 id="large-scale-order-dispatch-in-on-demand-ride-hailing-platforms-a-learning-and-planning-approach">Large-ScaleOrder Dispatch in On-Demand Ride-Hailing Platforms A Learning andPlanning Approach</h3><p>将强化学习算法应用于分单，使得系统可以更加关注整个全局的最优化，并且克服现有分单算法中存在的“短视”现象，寻求更大时间尺度上的最优。</p><p>将订单调度建模为一个大规模序列决策问题，每个独立的匹配决策基于两个因素：根据实时信息得到的司机服务这一单得到的即时奖励＋一个表征该决策对未来影响的额外因素。</p><p>分单：对于较短一个时间片<span class="math inline">\(t\)</span> ，有<span class="math inline">\(m\)</span>个待分配订单， <span class="math inline">\(n\)</span>个空闲司机，按照某种原则，将待分配订单分配给空闲司机。分单的目标是最大化成交总额(GrossMerchandiseVolume,GMV)。</p><h4 id="问题建模">问题建模</h4><p>将Markov Decision Process(MDP)用于建模序列决策问题：</p><p>目标：最大化收益gain <span class="math inline">\(G_t = \Sigma_{i=t}^T R_{t+1}\)</span></p><p>方法：学习价值函数 state-value function <span class="math inline">\(V_{\pi}(s)=\mathbb E_{\pi}[G_t|s_t=s]\)</span> 和action-value function <span class="math inline">\(Q_{\pi}(s,a)=\mathbbE_{\pi}[G_t|s_t=s,a_t=a]\)</span></p><p>MDP定义：</p><p>把每个独立的司机建模为一个agent，有利于简化其他定义。</p><p><strong><em>State</em></strong>. 把所有时间 <span class="math inline">\(T\)</span> 和所有区域 <span class="math inline">\(G\)</span>进行离散化，司机的状态可以定义为表征时空状态的二维向量<span class="math inline">\(s=(t,g)\in S, t\in T,g\in G\)</span>,所有状态集就是时间和空间的笛卡尔积 <span class="math inline">\(|S|=|T|\times |G|\)</span></p><p><strong><em>Action</em></strong>. 一是服务行为(servingaction)，指定司机去服务一个特定的订单，完成后得到订单的奖励；二是闲置行为(idleaction)，在该时间片内匹配不到任何订单，这一action会导致自动转换到下一轮分单且该轮分单奖励为0。</p><p><strong><em>Reward.</em></strong>考虑到预估价格和预计到达时间的不确定性，加入了折扣系数，即时奖励表示为<span class="math inline">\(R_\gamma=\sum_{t=0}^{T-1}\gamma^t \fracRT\)</span>.</p><p>举例，预估$30的订单，10min在接乘客，20min行驶，从A送到B，以10min为一个时间片，状态转移表示为<span class="math inline">\(s=(0,A)\rightarrows&#39;=(3,B)\)</span>，折扣系数<span class="math inline">\(\gamma=0.9\)</span>，那么最终的奖励为 <span class="math inline">\(R/T=30/3=10,r=10+10*0.9+10*0.9^2=27.1\)</span></p><p><strong><em>State transition.</em></strong>状态转移伴随行为发生,Temporal Difference(TD)更新规则如下：</p><p>对于idle action的司机:</p><p><span class="math inline">\(V(s)\leftarrow V(s)+\alpha[0+\gammaV(s&#39;)-V(s)], s=(t,g)\rightarrows&#39;=(t+1,g)\)</span>，时间片加一，地区不变；</p><p>对于serving action的司机:</p><p><span class="math inline">\(V(s)\leftarrow V(s)+\alpha[R_\gamma+\gamma^{\Delta t}V(s&#39;&#39;)-V(s)],s=(t,g)\rightarrows&#39;=(t+\Delta t,g_{dest})\)</span></p><h4 id="算法介绍">算法介绍</h4><p>实时订单分配算法 <span class="math display">\[\mathop{argmax}\limits_{a_{ij}} \sum_{i=0}^m\sum_{j=0}^nQ_{\pi}(i,j)a_{ij}\\s.t. \space \space \sum_{i=0}^ma_{ij}=1, j=1,2,3,...,n\\    \sum_{j=0}^na_{ij}=1, i=1,2,3,...,m\]</span> <span class="math inline">\(Q_{\pi}(i,j)\)</span>表示将订单<span class="math inline">\(j\)</span>分配给司机<span class="math inline">\(i\)</span>预期增加的收益，<span class="math inline">\(i=0\)</span>表示空司机的特殊状态，<span class="math inline">\(j=0\)</span>表示空订单的特殊状态。</p><p>学习时空价值过程中也有时间片(状态的划分，状态由时间索引和空间索引组成)，这个时间片一般比较大(几分钟)，而分单时间片一般比较小(比如几秒)，这是为了保证分单的实时性。这就导致了对于该分单轮次，轮空的司机来说，其状态是不变的(时间索引和空间索引都不变)，也就是说其增益价值为空，所以分单算法应该保证尽量不让司机轮空。因此，可以去掉这两个特殊的状态，问题变为带边权的最大二分图匹配问题。该问题可以使用KM(Kuhn-Munkres)算法求解。</p><p>采用advantage function trick, 减去了<span class="math inline">\(V(i)\)</span>连接到司机<span class="math inline">\(i\)</span>的边。advatangefunction的计算方式为期待收益减去保持在原来状态的期待价值，删除了二分图中的大多数边，有利于更快的计算。<span class="math display">\[\mathop{argmax}\limits_{a_{ij}} \sum_{i=1}^m\sum_{j=1}^nA_{\pi}(i,j)a_{ij}\\s.t.\quad \space \sum_{i=1}^ma_{ij}\le1, j=1,2,3,...,n\\    \sum_{j=1}^na_{ij}\le1, i=1,2,3,...,m\\    where\quad A_{\pi}(i,j)=\gamma^{\Deltat_j}V(s&#39;_{ij})-V(s_i)+R_{\gamma}(j)\quad is \space advantage\spacefunciton\]</span> advantage function中主要考虑以下四个因素：</p><p><strong><em>Order price.</em></strong> 订单j的价格越高，相应的<span class="math inline">\(R_{\gamma}(j)\)</span>也越高</p><p><strong><em>Drivers' location.</em></strong>未来更难接到订单(即当前价值低的司机，<span class="math inline">\(V(s_i)\)</span>小)更容易接到订单，司机当前的状态对应advantagefunction中的负面影响<span class="math inline">\(-V(s_i)\)</span></p><p><strong><em>Order destination.</em></strong>目的地为高价值区域的订单对应更高的<span class="math inline">\(V(s&#39;_{ij})\)</span></p><p><strong><em>Pickup distance.</em></strong>更远的接客距离会导致更晚的到达时间，增加了<span class="math inline">\(\Delta t_j\)</span>，增大了折扣</p><h4 id="算法流程">算法流程</h4><p>离线部分：</p><ol type="1"><li><p>收集历史数据中的订单信息，表示为强化学习中的四元组形式；</p></li><li><p>使用动态规划求解价值函数。将价值函数以查找表 (lookup table)形式保存以供线上使用。</p></li></ol><p>线上部分：</p><ol type="1"><li><p>收集待分配的司机和订单列表;</p></li><li><p>计算每个司乘匹配对应的动作价值数 (State-ActionFunction)，并以此为权重建立二分图;</p></li><li><p>将上述匹配权值作为权重嵌入KM算法，充分考虑接驾距离、服务分等因素，求解最优匹配，进入最终派单环节。</p></li></ol><p>迭代部分：</p><p>离线+线上，根据新积累的数据离线更新价值函数，和使用更新后的价值函数指导派单的过程。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Reinforcement Learning</tag>
      
      <tag>Order Dispatch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>个人静态网页博客部署记录</title>
    <link href="/2023/03/31/%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/"/>
    <url>/2023/03/31/%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>👀写在最前，从来没想过会有什么时候自己会需要写前端，大一的时候采访一个15年就毕业的做前端的学长，从他的博客里感受到前端好像是个不那么受待见、在大众眼里没什么技术性、薪资不是很高但其实又很重要的岗位，后来上的课也是没有一门与前端相关的，于是对前端的了解大概也就止步于此了。之前倒是经常看着同专业的人秉持着兴趣在做网页，佩服别人的同时却没有一点儿自己要动手尝试的想法，但是现在，为了完成<a href="https://github.com/X-lab2017/oss101/issues/33">第四讲开源作业</a>，还是<del>迫不得已</del>上路了。</p><p>✨没想到的是，在了解SSG框架的过程中，一边欣赏别人的主题一边学习框架的基础命令一边自己点开各种前端文件看个究竟，慢慢地觉得前端好有意思，可以根据自己的审美去设计网站结构，记录自己想要记录的东西，对于我这样一个啰哩叭嗦的人来说，<strong>一个静态网页博客真的可以作为一片用于记录和分享所有包括学习、生活中各种事情的自留地🌷</strong>，所以这次提交的网址不会是我的最终版本，这个网址在ddl之前是我的作业成果，在ddl之后就是属于我自己的blog啦~</p><p>📝因为是完全从零开始，所以会每一步的尝试和问题都仔细记录，下面就是我的动手实践全记录了。</p><h2 id="实践步骤">实践步骤</h2><h3 id="一选择ssg框架">一、选择SSG框架</h3><p>虽然助教建议先选择主题再选择框架，但在参考网上各类教程后我决定直接采用Hexo框架。由于之前没有接触过前端的内容，所以先学习了Hexo的基础操作，此处推荐Youtube上的Hexo教程<a href="https://youtu.be/A-muxF_6plc">Hexo-Static Site Generator</a>以及官方文档<a href="https://hexo.io/docs/">Documentation |Hexo</a>。</p><p>下载安装 <a href="https://nodejs.org/en">Node.js</a> 和 <a href="https://git-scm.com/">Git</a>后就可以通过在终端输入命令<code>$ npm install -g hexo-cli</code>安装Hexo，可以输入<code>hexo -v</code>查看是否安装成功。</p><h3 id="二选择主题">二、选择主题</h3><p>在<a href="https://hexo.io/themes/">Themes | Hexo</a>挑选喜欢的主题，在精挑细选后，我挑选了一款个人觉得还不错的主题(也就是很多人都在用的)<a href="https://github.com/fluid-dev/hexo-theme-fluid">hexo-theme-fluid</a>，</p><p>通过<code>npm install --save hexo-theme-fluid</code>可以直接安装最新版本的fluid，新建<code>_cpmfoh.fluid.yml</code>文件，复制主题的<code>_config,yml</code>中的内容到该文件中并在博客目录中的<code>_config.yml</code>中设置theme的值为fluid即可。</p><p>选择主题后就可以对网站进行个性化设计了~</p><h3 id="三个性化设计">三、个性化设计</h3><h4 id="创建关于页">创建关于页</h4><p><code>hexo new page about</code>添加about页面，创建成功后修改<code>/source/about/index.md</code>，添加 <code>layout</code>属性。然后可以自定义头像、个性签名以及自我介绍，设置GitHub、Steam主页链接及微信二维码等。</p><h4 id="更改bannersloganfavicon等">更改banner/slogan/favicon等</h4><p>在<code>_config.fluid.yml</code>中修改banner、favicon的图片和slogan的文本内容，同时在相应文件夹上传需要显示的图片文件，实现个人喜欢的风格呈现。</p><h4 id="上传个人文件">上传个人文件</h4><p>将想要上传的<code>.md</code>文件放入<code>_posts</code>文件夹中，在<code>img</code>文件夹下放入相关的图片，设置文件的tag、categories等实现不同文档的归档和标签设置，便于查找相关文件。</p><h3 id="四增加功能">四、增加功能</h3><h4 id="置顶博客">置顶博客</h4><p>通过设置该页Front-matter中<code>sticky</code>的值将该部署记录置顶</p><p><img src="/2023/03/31/%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/sticky_top.png"></p><h4 id="统计访问次数浏览量">统计访问次数/浏览量</h4><p>采用无需注册即可使用的不蒜子，通过将<code>_config.fluid.yml</code>中的<code>footer</code>下<code>statistics</code>的<code>enable</code>值设为True，如下所示添加<code>pv_format</code>和<code>uv_format</code>两行实现总访客数和总访问量的统计。</p><p><img src="/2023/03/31/%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/statistics.png"></p><h3 id="五部署网站">五、部署网站</h3><p>根据相关的通过GitHub部署hexo静态网站的教程，实现网站从本地仓库上传到GitHub仓库。首先将git与GitHub账号绑定，配置用户名和邮箱</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git config --global user.name <span class="hljs-string">&quot;Yukiho1028&quot;</span><br>git config --global user.email <span class="hljs-string">&quot;1479303796@qq.com&quot;</span><br></code></pre></td></tr></table></figure><p>然后生成ssh密钥</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa -C <span class="hljs-string">&quot;1479303796@qq.com&quot;</span><br></code></pre></td></tr></table></figure><p>将生成的<code>.ssh</code>文件夹中的id_rsa.pub密钥的内容复制，在GitHub新建SSHkey，title任意，key的内容即为复制的内容，粘贴后<code>Add SSH key</code>生成密钥。</p><p>安装<code>hexo-deployer-git</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install hexo-deployer-git --save<br></code></pre></td></tr></table></figure><p>然后在命令行依次输入以下指令生成网站、预览网站、部署网站即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g<br>hexo s<br>hexo d<br></code></pre></td></tr></table></figure><p>然后就可以成功访问<a href="https://yukiho1028.github.io/">我的blog</a>啦~</p><h3 id="六未来规划">六、未来规划</h3><ol type="1"><li><p>目前论文笔记中的公式渲染还存在部分问题没有解决，之后有时间再研究问题所在。</p></li><li><p>如果有朋友愿意的话，可以添加友链🔗。</p></li><li><p>开拓更多的categories，并在上面做一些笔记分享和生活记录。</p></li><li><p>添加更多的功能，e.g.添加评论功能。</p></li></ol><h2 id="问题记录">问题记录</h2><p>💭问题一：<code>hexo server</code>时报错<code>YAMLException: duplicated mapping key</code></p><p>解决方式：报错显示出现重复的键值对，发现在<code>_config.yml</code>中写了两次<code>theme: hexo-theme-fluid</code>，删除其中一行即可。</p><p>💭问题二：在部署网站到github时出现所有内容都被提交到master分支而不是main的问题(下图所示)，网站未能正常显示。</p><p><img src="/2023/03/31/%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/to_master.png"></p><p>解决方式：发现问题在于参考的教程中写把branch的值设成<code>master</code>而应该要推送<code>main</code>,所以如下图所示更改branch的值为<code>main</code>，重新部署即可解决。</p><p><img src="/2023/03/31/%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/master2main.png"></p><p>💭问题三：如下图所示，论文笔记中的公式都无法正常渲染。</p><p><img src="/2023/03/31/%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/formulation-error.png"></p><p>解决方式：参考<a href="https://hexo.fluid-dev.com/docs/guide/#latex-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F">Hexo配置指南-Latex公式</a>，在<code>_config.yml</code>中设置<code>math</code>下的<code>enable</code>和<code>specific</code>为true，并在所有需要显示公式的<code>.md</code>文档的Front-matter中添加<code>math:true</code>，然后输入以下指令更换渲染器，最后安装Pandoc，输入<code>hexo clean</code>即可正常显示公式。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm uninstall hexo-renderer-marked --save<br>npm install hexo-renderer-pandoc --save<br></code></pre></td></tr></table></figure><p>💭问题四：如下图所示，更改渲染器后发现图片无法正常显示(本人写代码的日常，改了这个错那个)</p><p><img src="/2023/03/31/%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/img-error.png"></p><p>解决方式：参考<a href="https://www.jianshu.com/p/04814a816caf">hexo无法显示markdown图片解决方法</a>，设置<code>_confi.yml</code>中的<code>post_asset_folder</code>的值为true，并通过<code>npm install https://github.com/7ym0n/hexo-asset-image --save</code>安装图片路径转换插件，之后每次新建文档<code>hexo new filename</code>都会同时生成一个<code>filename</code>的文件夹，在其中放入图片，在博文中以<code>![](filename/img_name.png)</code>格式引用图片，即可正常显示。</p><h2 id="参考链接">参考链接</h2><p><a href="https://www.jianshu.com/p/189fd945f38f/">搭建个人博客-hexo+github详细完整步骤- 简书 (jianshu.com)</a></p><p><a href="https://www.cnblogs.com/xrblog/p/11587356.html#:~:text=%E6%8C%91%E9%80%89%E5%96%9C%E6%AC%A2%E7%9A%84%E7%BD%91%E9%A1%B5%E4%B8%BB%E9%A2%98%201%20%E5%9C%A8%20Hexo%E4%B8%BB%E9%A2%98%20%E4%B8%AD%E9%80%89%E6%8B%A9%E6%88%91%E4%BB%AC%E5%96%9C%E6%AC%A2%E7%9A%84%E4%B8%BB%E9%A2%98%EF%BC%8C%E8%BF%99%E9%87%8C%E6%88%91%E9%80%89%E6%8B%A9%E7%9A%84%E6%98%AF%20Anatole%20%E4%B8%BB%E9%A2%98%E3%80%82%202,--save%20hexo-render-pug%20hexo-generator-archive%20hexo-generator-tag%20hexo-generator-index%20hexo-generator-category%20%EF%BC%8C%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE%E5%BF%85%E8%A6%81%E7%9A%84%E6%8F%92%E4%BB%B6%2C%E5%A4%A7%E6%A6%82%E4%B8%80%E5%88%86%E9%92%9F%E5%B7%A6%E5%8F%B3%E3%80%82%20%E6%9B%B4%E5%A4%9A%E9%A1%B9%E7%9B%AE">hexo教程（四）——更改hexo主题- 月如霜 - 博客园 (cnblogs.com)</a></p><p><a href="https://hexo.fluid-dev.com/docs/guide/">配置指南 | HexoFluid 用户手册 (fluid-dev.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/370635512">超详细 Hexo + GithubPages 博客搭建教程</a></p>]]></content>
    
    
    <categories>
      
      <category>学习记录</category>
      
    </categories>
    
    
    <tags>
      
      <tag>SSG</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
